# Vision-Prosthesis
# Computer Vision & EMG-Based Prosthetic Hand with Haptic Feedback

## Overview
This project explores the design and development of a prosthetic hand that uses computer vision and electromyography (EMG) signals to determine grip patterns, combined with haptic feedback to enhance the userâ€™s sense of touch.

## Features
- **Computer Vision**: Embedded camera for object recognition.
- **EMG Signals**: Control through signals from the remaining muscles.
- **Haptic Feedback**: Users can feel texture, pressure, and other tactile information.
- **Mobile Application**: Allows users to control the prosthetic hand via a mobile app.

## Contributions
- **Research & Literature Review**: Conducted an in-depth review of existing technologies and methods in prosthetics, computer vision, and EMG-based control systems.
- **YOLO Implementation**: Integrated **YOLO (You Only Look Once)** for object detection on a **Raspberry Pi** to enable real-time object recognition and decision-making.
- **Mobile App Development**: Created a mobile application using **Flutter** to give users control over the prosthetic hand, enabling real-time adjustments and feedback.

## Files
- [Project Report](Final%20Copy%20-%20Vision%20Prosthesis.pdf): Full report of the project.

